{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76e878d4",
   "metadata": {},
   "source": [
    "# Exploratory Dataset Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce35c564",
   "metadata": {},
   "source": [
    "### Package Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c797fcd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pprint\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "# list manipulations/count\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "# Regular expressions\n",
    "import re\n",
    "\n",
    "# Natural Language toolkit\n",
    "\n",
    "import nltk\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import SnowballStemmer\n",
    "from bs4 import BeautifulSoup\n",
    "import string\n",
    "\n",
    "# Language detection package\n",
    "\n",
    "import pycld2 as cld2\n",
    "\n",
    "\n",
    "# Countvectorizer from Sklearn\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Model\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "# Evaluation report\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c4a29c",
   "metadata": {},
   "source": [
    "### Dataset importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be65d15e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I'm too old to be traded in .</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mother said you could always tell a lady by he...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I always said I'd leave off when the time came .</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>He'll be safe with me .</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lay off .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  emotion\n",
       "0                      I'm too old to be traded in .        6\n",
       "1  Mother said you could always tell a lady by he...        8\n",
       "2   I always said I'd leave off when the time came .        6\n",
       "3                            He'll be safe with me .        2\n",
       "4                                          Lay off .        1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"/Users/goncalogomes/Documents/GitHub/Text-Mining-2022/Data-20220517/training_set.txt\",sep='\\t' ) # header=0\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9d0c047",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14000, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62cb2b47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What happens to the gold in our safe ?</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Natural to get cold feet .</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not very lucky , is he ?</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 sentence  emotion\n",
       "0  What happens to the gold in our safe ?        4\n",
       "1              Natural to get cold feet .        8\n",
       "2                Not very lucky , is he ?        7"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## validation set importing\n",
    "\n",
    "val = open(\"/Users/goncalogomes/Documents/GitHub/Text-Mining-2022/Data-20220517/dev_set.txt\", \"r\")\n",
    "val = pd.read_csv(\"/Users/goncalogomes/Documents/GitHub/Text-Mining-2022/Data-20220517/dev_set.txt\",sep='\\t')\n",
    "val.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dfe9c4f",
   "metadata": {},
   "source": [
    "###  Label counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40a0f0f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emotion</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2095</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         sentence\n",
       "emotion          \n",
       "1            2999\n",
       "2            2129\n",
       "3            1343\n",
       "4            1442\n",
       "5            1470\n",
       "6            1384\n",
       "7            1138\n",
       "8            2095"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby('emotion').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72f2d809",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='emotion'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlwAAAFvCAYAAACfGhUuAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAbcElEQVR4nO3debBedZ3n8fcHkiaKjBCIDBDopLoDbVAJkIlQWgpEdkuUchQcFZc2XSWIVDvK4oLSTQ09Y2u1oMykhwhaKsFtSEMGCOgMOiIQIM3qElkkECACIoIsge/88ZzQl3CT3CT3d5+b3Per6tZznt/5nXO+51Ry88n5nSVVhSRJktrZot8FSJIkbe4MXJIkSY0ZuCRJkhozcEmSJDVm4JIkSWpsXL8LWJsddtihpkyZ0u8yJEmS1umGG274XVVNGmzeqA5cU6ZMYfHixf0uQ5IkaZ2S3LOmeQ4pSpIkNWbgkiRJaszAJUmS1NiovoZLkiQNv2effZZly5bx1FNP9buUTdKECROYPHky48ePH/IyBi5JksaYZcuWsc022zBlyhSS9LucTUpV8fDDD7Ns2TKmTp065OUcUpQkaYx56qmn2H777Q1bGyAJ22+//XqfHTRwSZI0Bhm2NtyGHDsDlyRJUmNewyVJ0hg35ZRLh3V9d5915LCubzBLlizh/vvv54gjjmi+reHgGS5JkrTJWbJkCQsXLux3GUNm4JIkSSPqiSee4Mgjj2SvvfbiNa95DfPnz+eGG27gzW9+M/vuuy+HHnooy5cvB+CAAw7g5JNPZtasWey+++785Cc/4ZlnnuFzn/sc8+fPZ8aMGcyfP58nnniCD33oQ8yaNYu9996biy++GIDzzz+fo48+msMOO4xp06bxqU996oU6LrvsMvbZZx/22msvZs+e/UJtg61nY61zSDHJBOBqYKuu//eq6vQkU4ELge2BG4D3VdUzSbYCvgHsCzwMvLuq7u7WdSrwYeA54MSqunxY9kKSJG0yLrvsMnbeeWcuvbQ3lPnYY49x+OGHc/HFFzNp0iTmz5/Ppz/9aebNmwfAypUrue6661i4cCFf+MIXuPLKKznjjDNYvHgx55xzDgCnnXYaBx10EPPmzeP3v/89s2bN4i1veQvQOxt20003sdVWW7HHHnvwsY99jAkTJvCRj3yEq6++mqlTp/LII48AcOaZZw66nq233nqj9nko13A9DRxUVX9MMh74aZL/Dfwt8OWqujDJf6cXpM7tPh+tqr9McgzwD8C7k0wHjgH2BHYGrkyye1U9t1F7IEmSNimvfe1r+cQnPsHJJ5/MW9/6VrbbbjtuvfVWDj74YACee+45dtpppxf6H3300QDsu+++3H333YOu84orrmDBggV88YtfBHqPvvjtb38LwOzZs3nlK18JwPTp07nnnnt49NFHedOb3vTCs7QmTpy41vW8+tWv3qh9XmfgqqoC/th9Hd/9FHAQ8J6u/QLg8/QC11HdNMD3gHPSu3/yKODCqnoauCvJUmAWcM1G7YEkSdqk7L777tx4440sXLiQz3zmMxx00EHsueeeXHPN4JFgq622AmDLLbdk5cqVg/apKr7//e+zxx57vKj92muvfWH5da1jbevZWEO6SzHJlvSGDf8S+CrwG+D3VbWq4mXALt30LsC9XdErkzxGb9hxF+DnA1Y7cJmB25oDzAHYbbfd1nN3Bjfcd19sjJG4c0OSpNHs/vvvZ+LEibz3ve9l22235Wtf+xorVqzgmmuuYf/99+fZZ5/lV7/6FXvuueca17HNNtvw+OOPv/D90EMP5eyzz+bss88mCTfddBN77733Gpffb7/9+OhHP8pdd931wpDixIkT13s9QzWkwNUN+81Isi3wQ+CvNnrLa97WXGAuwMyZM6vVdiRJUs9Inwy45ZZb+OQnP8kWW2zB+PHjOffccxk3bhwnnngijz32GCtXruSkk05aa+A68MADOeuss5gxYwannnoqn/3sZznppJN43etex/PPP8/UqVO55JJL1rj8pEmTmDt3LkcffTTPP/88r3rVq1i0aNF6r2eo0hsxXI8Fks8BfwJOBv59dxZrf+DzVXVoksu76WuSjAMeACYBpwBU1X/p1vNCvzVta+bMmbV48eIN2a8X8QyXJEn/5o477tjoa5LGusGOYZIbqmrmYP3X+ViIJJO6M1skeRlwMHAH8GPgnV2344BV900u6L7Tzf9Rdx3YAuCYJFt1dzhOA64b+q5JkiRtmoYypLgTcEF3HdcWwEVVdUmS24ELk/w9cBNwXtf/POCb3UXxj9C7M5Gqui3JRcDtwErgeO9QlCRJY8FQ7lK8GXjJ1WJVdSe9uwxXb38K+I9rWNeZwJnrX6YkSRpOVeULrDfQ+l6OBT5pXpKkMWfChAk8/PDDGxQcxrqq4uGHH2bChAnrtZwvr5YkaYyZPHkyy5YtY8WKFf0uZZM0YcIEJk+evF7LGLgkSRpjxo8f/8IT1jUyHFKUJElqzMAlSZLUmIFLkiSpMQOXJElSYwYuSZKkxgxckiRJjRm4JEmSGjNwSZIkNWbgkiRJaszAJUmS1JiBS5IkqTEDlyRJUmMGLkmSpMYMXJIkSY0ZuCRJkhozcEmSJDVm4JIkSWrMwCVJktSYgUuSJKkxA5ckSVJjBi5JkqTGDFySJEmNGbgkSZIaM3BJkiQ1ZuCSJElqzMAlSZLUmIFLkiSpMQOXJElSYwYuSZKkxgxckiRJjRm4JEmSGjNwSZIkNWbgkiRJaszAJUmS1JiBS5IkqTEDlyRJUmMGLkmSpMYMXJIkSY0ZuCRJkhpbZ+BKsmuSHye5PcltST7etX8+yX1JlnQ/RwxY5tQkS5P8MsmhA9oP69qWJjmlzS5JkiSNLuOG0Gcl8ImqujHJNsANSRZ1875cVV8c2DnJdOAYYE9gZ+DKJLt3s78KHAwsA65PsqCqbh+OHZEkSRqt1hm4qmo5sLybfjzJHcAua1nkKODCqnoauCvJUmBWN29pVd0JkOTCrq+BS5IkbdbW6xquJFOAvYFru6YTktycZF6S7bq2XYB7Byy2rGtbU/vq25iTZHGSxStWrFif8iRJkkalIQeuJK8Avg+cVFV/AM4F/gKYQe8M2D8OR0FVNbeqZlbVzEmTJg3HKiVJkvpqKNdwkWQ8vbD1rar6AUBVPThg/j8Dl3Rf7wN2HbD45K6NtbRLkiRttoZyl2KA84A7qupLA9p3GtDtHcCt3fQC4JgkWyWZCkwDrgOuB6YlmZrkz+hdWL9geHZDkiRp9BrKGa43AO8DbkmypGs7DTg2yQyggLuBvwGoqtuSXETvYviVwPFV9RxAkhOAy4EtgXlVdduw7YkkSdIoNZS7FH8KZJBZC9eyzJnAmYO0L1zbcpIkSZsjnzQvSZLUmIFLkiSpMQOXJElSYwYuSZKkxgxckiRJjRm4JEmSGjNwSZIkNWbgkiRJaszAJUmS1JiBS5IkqTEDlyRJUmMGLkmSpMYMXJIkSY0ZuCRJkhozcEmSJDVm4JIkSWrMwCVJktSYgUuSJKkxA5ckSVJjBi5JkqTGDFySJEmNGbgkSZIaM3BJkiQ1ZuCSJElqzMAlSZLUmIFLkiSpMQOXJElSYwYuSZKkxgxckiRJjRm4JEmSGjNwSZIkNWbgkiRJaszAJUmS1Ni4fheg/plyyqX9LuEFd591ZL9LkCSpGc9wSZIkNWbgkiRJaswhRUmS1Bdj6dIWz3BJkiQ1ZuCSJElqzMAlSZLUmIFLkiSpMQOXJElSYwYuSZKkxtYZuJLsmuTHSW5PcluSj3ftE5MsSvLr7nO7rj1JvpJkaZKbk+wzYF3Hdf1/neS4drslSZI0egzlDNdK4BNVNR3YDzg+yXTgFOCqqpoGXNV9BzgcmNb9zAHOhV5AA04HXg/MAk5fFdIkSZI2Z+sMXFW1vKpu7KYfB+4AdgGOAi7oul0AvL2bPgr4RvX8HNg2yU7AocCiqnqkqh4FFgGHDefOSJIkjUbrdQ1XkinA3sC1wI5Vtbyb9QCwYze9C3DvgMWWdW1ral99G3OSLE6yeMWKFetTniRJ0qg05MCV5BXA94GTquoPA+dVVQE1HAVV1dyqmllVMydNmjQcq5QkSeqrIQWuJOPpha1vVdUPuuYHu6FCus+Huvb7gF0HLD65a1tTuyRJ0mZtKHcpBjgPuKOqvjRg1gJg1Z2GxwEXD2h/f3e34n7AY93Q4+XAIUm26y6WP6RrkyRJ2qyNG0KfNwDvA25JsqRrOw04C7goyYeBe4B3dfMWAkcAS4EngQ8CVNUjSf4OuL7rd0ZVPTIcOyFJkjSarTNwVdVPgaxh9uxB+hdw/BrWNQ+Ytz4FSpIkbep80rwkSVJjBi5JkqTGDFySJEmNGbgkSZIaM3BJkiQ1ZuCSJElqzMAlSZLUmIFLkiSpMQOXJElSYwYuSZKkxgxckiRJjRm4JEmSGjNwSZIkNWbgkiRJaszAJUmS1JiBS5IkqTEDlyRJUmMGLkmSpMYMXJIkSY0ZuCRJkhozcEmSJDVm4JIkSWrMwCVJktSYgUuSJKkxA5ckSVJjBi5JkqTGDFySJEmNGbgkSZIaM3BJkiQ1ZuCSJElqzMAlSZLUmIFLkiSpMQOXJElSYwYuSZKkxgxckiRJjRm4JEmSGjNwSZIkNWbgkiRJaszAJUmS1JiBS5IkqTEDlyRJUmMGLkmSpMYMXJIkSY2tM3AlmZfkoSS3Dmj7fJL7kizpfo4YMO/UJEuT/DLJoQPaD+valiY5Zfh3RZIkaXQayhmu84HDBmn/clXN6H4WAiSZDhwD7Nkt87UkWybZEvgqcDgwHTi26ytJkrTZG7euDlV1dZIpQ1zfUcCFVfU0cFeSpcCsbt7SqroTIMmFXd/b179kSZKkTcvGXMN1QpKbuyHH7bq2XYB7B/RZ1rWtqf0lksxJsjjJ4hUrVmxEeZIkSaPDhgauc4G/AGYAy4F/HK6CqmpuVc2sqpmTJk0artVKkiT1zTqHFAdTVQ+umk7yz8Al3df7gF0HdJ3ctbGWdkmSpM3aBgWuJDtV1fLu6zuAVXcwLgC+neRLwM7ANOA6IMC0JFPpBa1jgPdsTOGS1G9TTrm03yW84O6zjux3CZLWYp2BK8l3gAOAHZIsA04HDkgyAyjgbuBvAKrqtiQX0bsYfiVwfFU9163nBOByYEtgXlXdNtw7I0mSNBoN5S7FYwdpPm8t/c8EzhykfSGwcL2qkyRJ2gxs0JCipLHFoTNJ2ji+2keSJKkxA5ckSVJjBi5JkqTGDFySJEmNGbgkSZIa8y5FSdKw8q5W6aU8wyVJktSYgUuSJKkxA5ckSVJjXsMlDeC1J5KkFjzDJUmS1JiBS5IkqTEDlyRJUmMGLkmSpMYMXJIkSY0ZuCRJkhozcEmSJDVm4JIkSWrMwCVJktSYgUuSJKkxA5ckSVJjBi5JkqTGDFySJEmNGbgkSZIaM3BJkiQ1ZuCSJElqzMAlSZLUmIFLkiSpMQOXJElSYwYuSZKkxgxckiRJjY3rdwGSJG3uppxyab9LeMHdZx3Z7xLGJM9wSZIkNWbgkiRJaszAJUmS1JiBS5IkqTEDlyRJUmMGLkmSpMYMXJIkSY0ZuCRJkhozcEmSJDVm4JIkSWpsnYErybwkDyW5dUDbxCSLkvy6+9yua0+SryRZmuTmJPsMWOa4rv+vkxzXZnckSZJGn6Gc4TofOGy1tlOAq6pqGnBV9x3gcGBa9zMHOBd6AQ04HXg9MAs4fVVIkyRJ2tytM3BV1dXAI6s1HwVc0E1fALx9QPs3qufnwLZJdgIOBRZV1SNV9SiwiJeGOEmSpM3Shl7DtWNVLe+mHwB27KZ3Ae4d0G9Z17am9pdIMifJ4iSLV6xYsYHlSZIkjR4bfdF8VRVQw1DLqvXNraqZVTVz0qRJw7VaSZKkvtnQwPVgN1RI9/lQ134fsOuAfpO7tjW1S5IkbfY2NHAtAFbdaXgccPGA9vd3dyvuBzzWDT1eDhySZLvuYvlDujZJkqTN3rh1dUjyHeAAYIcky+jdbXgWcFGSDwP3AO/qui8EjgCWAk8CHwSoqkeS/B1wfdfvjKpa/UJ8SZKkzdI6A1dVHbuGWbMH6VvA8WtYzzxg3npVJ0mStBnwSfOSJEmNGbgkSZIaM3BJkiQ1ZuCSJElqzMAlSZLUmIFLkiSpMQOXJElSYwYuSZKkxgxckiRJjRm4JEmSGjNwSZIkNWbgkiRJaszAJUmS1JiBS5IkqTEDlyRJUmMGLkmSpMYMXJIkSY0ZuCRJkhozcEmSJDVm4JIkSWrMwCVJktSYgUuSJKkxA5ckSVJjBi5JkqTGDFySJEmNGbgkSZIaM3BJkiQ1ZuCSJElqzMAlSZLUmIFLkiSpMQOXJElSYwYuSZKkxgxckiRJjRm4JEmSGjNwSZIkNWbgkiRJaszAJUmS1JiBS5IkqTEDlyRJUmMGLkmSpMYMXJIkSY0ZuCRJkhozcEmSJDW2UYEryd1JbkmyJMnirm1ikkVJft19bte1J8lXkixNcnOSfYZjByRJkka74TjDdWBVzaiqmd33U4CrqmoacFX3HeBwYFr3Mwc4dxi2LUmSNOq1GFI8Crigm74AePuA9m9Uz8+BbZPs1GD7kiRJo8rGBq4CrkhyQ5I5XduOVbW8m34A2LGb3gW4d8Cyy7q2F0kyJ8niJItXrFixkeVJkiT137iNXP6NVXVfklcBi5L8YuDMqqoktT4rrKq5wFyAmTNnrteykiRJo9FGneGqqvu6z4eAHwKzgAdXDRV2nw913e8Ddh2w+OSuTZIkabO2wYErydZJtlk1DRwC3AosAI7ruh0HXNxNLwDe392tuB/w2IChR0mSpM3Wxgwp7gj8MMmq9Xy7qi5Lcj1wUZIPA/cA7+r6LwSOAJYCTwIf3IhtS5IkbTI2OHBV1Z3AXoO0PwzMHqS9gOM3dHuSJEmbKp80L0mS1JiBS5IkqTEDlyRJUmMGLkmSpMYMXJIkSY0ZuCRJkhozcEmSJDVm4JIkSWrMwCVJktSYgUuSJKkxA5ckSVJjBi5JkqTGDFySJEmNGbgkSZIaM3BJkiQ1ZuCSJElqzMAlSZLUmIFLkiSpMQOXJElSYwYuSZKkxgxckiRJjRm4JEmSGjNwSZIkNWbgkiRJaszAJUmS1JiBS5IkqTEDlyRJUmMGLkmSpMYMXJIkSY0ZuCRJkhozcEmSJDVm4JIkSWrMwCVJktSYgUuSJKkxA5ckSVJjBi5JkqTGDFySJEmNGbgkSZIaM3BJkiQ1ZuCSJElqzMAlSZLUmIFLkiSpsREPXEkOS/LLJEuTnDLS25ckSRppIxq4kmwJfBU4HJgOHJtk+kjWIEmSNNJG+gzXLGBpVd1ZVc8AFwJHjXANkiRJIypVNXIbS94JHFZVf919fx/w+qo6YUCfOcCc7usewC9HrMC12wH4Xb+LGIU8LoPzuAzO4/JSHpPBeVwG53EZ3Gg5Ln9eVZMGmzFupCtZl6qaC8ztdx2rS7K4qmb2u47RxuMyOI/L4DwuL+UxGZzHZXAel8FtCsdlpIcU7wN2HfB9ctcmSZK02RrpwHU9MC3J1CR/BhwDLBjhGiRJkkbUiA4pVtXKJCcAlwNbAvOq6raRrGEjjLphzlHC4zI4j8vgPC4v5TEZnMdlcB6XwY364zKiF81LkiSNRT5pXpIkqTEDlyRJUmMGLkmSpMYMXJIkSY0ZuLRekvxVktlJXrFa+2H9qmk0SDIryX/opqcn+dskR/S7rtEkyTf6XcNok+SN3Z+VQ/pdSz8leX2Sf9dNvyzJF5L8S5J/SPLKftfXL0lOTLLrunuOHUn+LMn7k7yl+/6eJOckOT7J+H7Xtzbepbieknywqr7e7zr6IcmJwPHAHcAM4ONVdXE378aq2qeP5fVNktPpvZB9HLAIeD3wY+Bg4PKqOrOP5fVFktWfrxfgQOBHAFX1thEvahRIcl1VzeqmP0Lv79MPgUOAf6mqs/pZX78kuQ3Yq3t00FzgSeB7wOyu/ei+FtgnSR4DngB+A3wH+G5VrehvVf2V5Fv0fte+HPg98ArgB/T+rKSqjutfdWtn4FpPSX5bVbv1u45+SHILsH9V/THJFHq/EL9ZVf+U5Kaq2ru/FfZHd1xmAFsBDwCTq+oPSV4GXFtVr+tnff2Q5EbgduB/AkUvcH2H3sOOqar/27/q+mfg35Mk1wNHVNWKJFsDP6+q1/a3wv5IckdVvbqbftF/3pIsqaoZfSuuj5LcBOwLvAV4N/A24AZ6f5d+UFWP97G8vkhyc1W9Lsk4em+q2bmqnksS4F9H8+/bUfcuxdEgyc1rmgXsOJK1jDJbVNUfAarq7iQHAN9L8uf0js1YtbKqngOeTPKbqvoDQFX9Kcnzfa6tX2YCHwc+DXyyqpYk+dNYDVoDbJFkO3qXc2TV2YqqeiLJyv6W1le3Dhg9+NckM6tqcZLdgWf7XVwfVVU9D1wBXNENmR0OHAt8ERj0JcmbuS26N9VsTe8s1yuBR+j9h3dUDykauAa3I3Ao8Ohq7QF+NvLljBoPJplRVUsAujNdbwXmAWPyf+adZ5K8vKqepPe/UQC6a0/GZODq/pH4cpLvdp8P4u8b6P3jcAO93yWVZKeqWt5dEzmW/9Py18A/JfkM8DvgmiT3Avd288aqF/2ZqKpn6b0Ob0GSl/enpL47D/gFvbfVfBr4bpI7gf2AC/tZ2Lo4pDiIJOcBX6+qnw4y79tV9Z4+lNV3SSbTO5vzwCDz3lBV/68PZfVdkq2q6ulB2ncAdqqqW/pQ1qiS5EjgDVV1Wr9rGY26fzx3rKq7+l1LP3UXzk+lF86XVdWDfS6pr5LsXlW/6ncdo02SnQGq6v4k29Ibcv1tVV3X18LWwcAlSZLUmI+FkCRJaszAJUmS1JiBS9KYlWTGwAfUJnlbklP6WZOkzZPXcEkas5J8AJhZVSf0uxZJmzfPcEnaZCR5b5LrkixJ8j+SbJnkj0n+W5LbklzZvWbp/yS5M8nbuuUmJPl6kluS3JTkwO5ZPmcA7+7W9+4kH0hyTrfMlCQ/SnJzkquS7Na1n5/kK0l+1m3jnf07IpI2FQYuSZuEJK+m97TtN3RPHn8O+E/0HoD4o6raE3gc+Ht6r1V6B71ABb1X6FT3JPdjgQvo/f77HDC/qmZU1fzVNnk2cEH35OpvAV8ZMG8n4I3AW4Ex+ToeSevHBxFK2lTMpvdg2et7b/HgZcBDwDPAZV2fW4Cnq+rZ7pVLU7r2N9ILUFTVL5LcA+y+ju3tD6x6h983gf86YN7/6h7uenuSsfz2CUlDZOCStKkIvTNOp76oMfnP9W8Xoz4PPA29p91371trYeCDbsfyE+IlDZFDipI2FVcB70zyKoAkE7v3eA7FT+gNP9K9n2834Jf0hiC3WcMyP6N72Xa37E82sG5JMnBJ2jRU1e3AZ+i9xPdmYBG9a6mG4mv0Xnp7CzAf+ED3OqYfA9NXXTS/2jIfAz7Ybet99F7GLUkbxMdCSJIkNeYZLkmSpMYMXJIkSY0ZuCRJkhozcEmSJDVm4JIkSWrMwCVJktSYgUuSJKmx/w9u7OgvM98YZgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the cardinality of the different 'emotion' labels\n",
    "\n",
    "data.groupby('emotion').count().plot.bar(figsize=(10,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "061b80da",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Or by using Professors code - Word count\n",
    "\n",
    "def label_counter(dataframe, field):\n",
    "    \"\"\"\n",
    "    Function that receives a dataframe and the field whose labels you want to count, and\n",
    "    returns the amount of examples with those labels in the Pandas dataframe.\n",
    "    \"\"\"    \n",
    "    return dataframe[field].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "047aa770",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    2999\n",
       "2    2129\n",
       "8    2095\n",
       "5    1470\n",
       "4    1442\n",
       "6    1384\n",
       "3    1343\n",
       "7    1138\n",
       "Name: emotion, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_counter(data, 'emotion')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521c3611",
   "metadata": {},
   "source": [
    "## Word Counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7406e903",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_counter(text_list):\n",
    "    \"\"\"\n",
    "    Function that receives a list of strings and returns the (absolute) frequency of each word in that list of strings.\n",
    "    \"\"\"\n",
    "    words_in_df = ' '.join(text_list).split()\n",
    "    \n",
    "    # Count all words \n",
    "    freq = pd.Series(words_in_df).value_counts()\n",
    "    return freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "510a16ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ".           10600\n",
       ",            5738\n",
       "you          3502\n",
       "I            3208\n",
       "to           2862\n",
       "the          2703\n",
       "?            2696\n",
       "a            2320\n",
       "!            1608\n",
       "[PERSON]     1386\n",
       "of           1358\n",
       "and          1266\n",
       "me           1195\n",
       "it           1193\n",
       "that         1156\n",
       "in           1083\n",
       "You           950\n",
       "is            902\n",
       "for           847\n",
       "be            761\n",
       "this          757\n",
       "I'm           738\n",
       "have          727\n",
       "your          690\n",
       "my            678\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counter(list(data['sentence']))[:25]\n",
    "\n",
    "# The majority of the top 25 most frequent words are either ponctuation or stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6718792",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_language(data):\n",
    "    \"\"\" Function that receives a dataset as input, and retrieves as an output the different \n",
    "    languages that exists inside the dataset and the number of lines in which the language\n",
    "    is detected.\n",
    "    \"\"\"    \n",
    "    \n",
    "    final_list=[]\n",
    "    for i in data.index:\n",
    "        _,_,detected_language= list(cld2.detect((data['sentence'][i])))\n",
    "        final_list.append(detected_language[0])\n",
    "    final_list\n",
    "    language_list = []\n",
    "    for i in range(len(final_list)):\n",
    "        temp_lang = language[i][0]\n",
    "        language_list.append(temp_lang)\n",
    "    language_list\n",
    "    return Counter(language_list).most_common()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "467ab3ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#check_language(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed8ce897",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.iloc[1345]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002b9a4f",
   "metadata": {},
   "source": [
    "## Models as benchmark\n",
    "\n",
    "- **Weaker Baseline**: \n",
    "    - Pre-processing: Removing everything but letters, ‘?’ and ‘!’; stemming; stop word removal.\n",
    "    - CountVectorizer + KNN\n",
    "    - With Accuracy of 27%\n",
    "- **Stronger Baseline**:\n",
    "    - preprocessing\n",
    "    - CountVectorizer\n",
    "    - SVC ( Linear Kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596611a3",
   "metadata": {},
   "source": [
    "# NLP Pipeline - Weaker Baseline\n",
    "\n",
    "- Pre-processing: Removing everything but letters, ‘?’ and ‘!’; stemming; stop word removal.\n",
    "    - CountVectorizer + KNN\n",
    "    - With Accuracy of 27%\n",
    "\n",
    "## Initial Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c582ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = set(stopwords.words('english'))\n",
    "exclude = set(string.punctuation)\n",
    "lemma = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d33c4fde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Size of unique stop words\n",
    "\n",
    "len(stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "98d3cb6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ponctuation unique characters inside exclude set\n",
    "\n",
    "len(exclude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b91c5be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm too old to be traded in .\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['sentence'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c977ad1",
   "metadata": {},
   "source": [
    "### Clean function\n",
    "\n",
    "- Lower cases\n",
    "- apply stemmatization/lemmatization \n",
    "- Remove numerical data and punctuation\n",
    "- Remove tags (with beautifulsoup)\n",
    "\n",
    "\n",
    "(tdqm - Instantly make your loops show a smart progress meter - just wrap any iterable with tqdm(iterable), and you're done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "540bd657",
   "metadata": {},
   "outputs": [],
   "source": [
    "snowball_stemmer = SnowballStemmer('english')\n",
    "\n",
    "def clean(text_list, lemmatize, stemmer):\n",
    "    \"\"\"\n",
    "    Function that a receives a list of strings and preprocesses it.\n",
    "    \n",
    "    :param text_list: List of strings.\n",
    "    :param lemmatize: Tag to apply lemmatization if True.\n",
    "    :param stemmer: Tag to apply the stemmer if True.\n",
    "    \"\"\"\n",
    "    updates = []\n",
    "    for j in tqdm(range(len(text_list))):\n",
    "        \n",
    "        text = text_list[j]\n",
    "        \n",
    "        #LOWERCASE TEXT\n",
    "        text = text.lower()\n",
    "        \n",
    "        #REMOVE NUMERICAL DATA AND PUNCTUATION\n",
    "        text = re.sub(\"[^a-zA-Z!?]\", ' ', text) # falta ? e !\n",
    "        \n",
    "        #REMOVE STOP WORDS\n",
    "        text = \" \".join([word for word in text.split() if word not in stop])\n",
    "        \n",
    "        #REMOVE TAGS\n",
    "        text = BeautifulSoup(text).get_text()\n",
    "        \n",
    "        if lemmatize:\n",
    "            text = \" \".join(lemma.lemmatize(word) for word in text.split())\n",
    "        \n",
    "        if stemmer:\n",
    "            text = \" \".join(snowball_stemmer.stem(word) for word in text.split())\n",
    "        \n",
    "        updates.append(text)\n",
    "        \n",
    "    return updates\n",
    "\n",
    "def update_df(dataframe, list_updated):\n",
    "    dataframe.update(pd.DataFrame({\"sentence\": list_updated}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "31172087",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/39/q_mq0msj34lfxgvp_1tb5ngm0000gn/T/ipykernel_38534/1919345334.py:12: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for j in tqdm(range(len(text_list))):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a914dbcffaf74fc19644c803e6273ed6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Applying the cleaning function to the 'sentence' column of our dataset\n",
    "# Lemmer false\n",
    "# Stemmer true \n",
    "\n",
    "updated_data = clean(data['sentence'], lemmatize = True, stemmer = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eec7d2aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>old traded</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mother said could always tell lady hand</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>always said leave time came</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  sentence  emotion\n",
       "0                               old traded        6\n",
       "1  mother said could always tell lady hand        8\n",
       "2              always said leave time came        6"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Update the data frame\n",
    "\n",
    "update_df(data, updated_data)\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7cb77db",
   "metadata": {},
   "source": [
    "## Feature Extraction with bag-of-words\n",
    "\n",
    "- max_df -> When building the vocabulary ignore terms that have a document frequency strictly higher than the given threshold (corpus-specific stop words). If float, the parameter represents a proportion of documents, integer absolute counts. This parameter is ignored if vocabulary is not None."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0a49d778",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining CV\n",
    "\n",
    "#cv = CountVectorizer(max_df=0.9, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ad476373",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = cv.fit_transform(data[\"sentence\"])\n",
    "#y = np.array(data['emotion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "183d3f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32efd3a6",
   "metadata": {},
   "source": [
    "## Feature Extraction with TF-IDF\n",
    "\n",
    " - TF-IDF vectorizer, which penalizes words that appear several times across different documents. TF-IDF are word frequency scores that highlight words that are more important to the context rather than those that appear frequently across documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aa62cc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words=\"english\", max_df=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d189c267",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tfidf_vectorizer.fit_transform(data[\"sentence\"])\n",
    "y = np.array(data[\"emotion\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5048e2a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14000, 6380)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17131510",
   "metadata": {},
   "source": [
    "## Training the model with KNN classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9369fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#modelknn = KNeighborsClassifier(n_neighbors=5, weights='distance', algorithm='brute', leaf_size=30, p=2,\n",
    "                                         metric='cosine', metric_params=None, n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250f0455",
   "metadata": {},
   "outputs": [],
   "source": [
    "#modelknn.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c09f8b5",
   "metadata": {},
   "source": [
    "## Training the model with multinomial Navie Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ff2c1b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "modelnaive = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "356786c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelnaive.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51213656",
   "metadata": {},
   "source": [
    "## Testing the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d635bac7",
   "metadata": {},
   "source": [
    "### Applying the same pre-processing to the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "60b62b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/39/q_mq0msj34lfxgvp_1tb5ngm0000gn/T/ipykernel_38534/1919345334.py:12: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for j in tqdm(range(len(text_list))):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89117e0209654d62871b51218f966a3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "updated_val = clean(val['sentence'], lemmatize = True, stemmer = False)\n",
    "update_df(val, updated_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abaf512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cv transform no val set\n",
    "\n",
    "#Val = cv.transform(val['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5556f3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Val = tfidf_vectorizer.transform(val[\"sentence\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd469d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict = modelknn.predict(Val)\n",
    "#y = np.array(val['emotion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "807e104c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = modelnaive.predict(Val)\n",
    "y = np.array(val[\"emotion\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6634cd",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "772415ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.29      0.43       576\n",
      "           2       0.36      0.40      0.38       156\n",
      "           3       0.01      0.12      0.02         8\n",
      "           4       0.10      0.48      0.16        21\n",
      "           5       0.31      0.45      0.37        67\n",
      "           6       0.13      0.32      0.18        34\n",
      "           7       0.02      0.33      0.04         6\n",
      "           8       0.32      0.38      0.34       132\n",
      "\n",
      "    accuracy                           0.34      1000\n",
      "   macro avg       0.26      0.35      0.24      1000\n",
      "weighted avg       0.59      0.34      0.39      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (classification_report(predict, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9c3e46",
   "metadata": {},
   "source": [
    "## Models as benchmark\n",
    "\n",
    "- **Weaker Baseline**: \n",
    "    - Pre-processing: Removing everything but letters, ‘?’ and ‘!’; stemming; stop word removal.\n",
    "    - CountVectorizer + KNN\n",
    "    - With Accuracy of 27%\n",
    "- **Stronger Baseline**:\n",
    "    - preprocessing\n",
    "    - CountVectorizer\n",
    "    - SVC ( Linear Kernel)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9d1a5e",
   "metadata": {},
   "source": [
    "## Checking the present languages in the text - Pycld2 (UNDER CONSTRUCTION)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
