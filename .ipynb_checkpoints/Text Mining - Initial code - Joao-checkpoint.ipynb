{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76e878d4",
   "metadata": {},
   "source": [
    "# Exploratory Dataset Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce35c564",
   "metadata": {},
   "source": [
    "### Package Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c797fcd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pprint\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "# list manipulations/count\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "# Regular expressions\n",
    "import re\n",
    "\n",
    "# Natural Language toolkit\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import SnowballStemmer\n",
    "from bs4 import BeautifulSoup\n",
    "import string\n",
    "\n",
    "# Language detection package\n",
    "\n",
    "import pycld2 as cld2\n",
    "\n",
    "\n",
    "# Countvectorizer from Sklearn\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Model\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "# Evaluation report\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c4a29c",
   "metadata": {},
   "source": [
    "### Dataset importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "be65d15e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I'm too old to be traded in .</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mother said you could always tell a lady by he...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I always said I'd leave off when the time came .</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>He'll be safe with me .</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lay off .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  emotion\n",
       "0                      I'm too old to be traded in .        6\n",
       "1  Mother said you could always tell a lady by he...        8\n",
       "2   I always said I'd leave off when the time came .        6\n",
       "3                            He'll be safe with me .        2\n",
       "4                                          Lay off .        1"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"training_set.txt\",sep='\\t' ) # header=0\n",
    "data.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d9d0c047",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14000, 2)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "62cb2b47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What happens to the gold in our safe ?</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Natural to get cold feet .</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not very lucky , is he ?</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 sentence  emotion\n",
       "0  What happens to the gold in our safe ?        4\n",
       "1              Natural to get cold feet .        8\n",
       "2                Not very lucky , is he ?        7"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## validation set importing\n",
    "\n",
    "val = open(\"dev_set.txt\", \"r\")\n",
    "val = pd.read_csv(\"dev_set.txt\",sep='\\t')\n",
    "val.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dfe9c4f",
   "metadata": {},
   "source": [
    "###  Label counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "40a0f0f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emotion</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2095</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         sentence\n",
       "emotion          \n",
       "1            2999\n",
       "2            2129\n",
       "3            1343\n",
       "4            1442\n",
       "5            1470\n",
       "6            1384\n",
       "7            1138\n",
       "8            2095"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby('emotion').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "72f2d809",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='emotion'>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the cardinality of the different 'emotion' labels\n",
    "\n",
    "data.groupby('emotion').count().plot.bar(figsize=(10,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "061b80da",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Or by using Professors code - Word count\n",
    "\n",
    "def label_counter(dataframe, field):\n",
    "    \"\"\"\n",
    "    Function that receives a dataframe and the field whose labels you want to count, and\n",
    "    returns the amount of examples with those labels in the Pandas dataframe.\n",
    "    \"\"\"    \n",
    "    return dataframe[field].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "047aa770",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    2999\n",
       "2    2129\n",
       "8    2095\n",
       "5    1470\n",
       "4    1442\n",
       "6    1384\n",
       "3    1343\n",
       "7    1138\n",
       "Name: emotion, dtype: int64"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_counter(data, 'emotion')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521c3611",
   "metadata": {},
   "source": [
    "## Word Counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "7406e903",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_counter(text_list):\n",
    "    \"\"\"\n",
    "    Function that receives a list of strings and returns the (absolute) frequency of each word in that list of strings.\n",
    "    \"\"\"\n",
    "    words_in_df = ' '.join(text_list).split()\n",
    "    \n",
    "    # Count all words \n",
    "    freq = pd.Series(words_in_df).value_counts()\n",
    "    return freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "510a16ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ".           10600\n",
       ",            5738\n",
       "you          3502\n",
       "I            3208\n",
       "to           2862\n",
       "the          2703\n",
       "?            2696\n",
       "a            2320\n",
       "!            1608\n",
       "[PERSON]     1386\n",
       "of           1358\n",
       "and          1266\n",
       "me           1195\n",
       "it           1193\n",
       "that         1156\n",
       "in           1083\n",
       "You           950\n",
       "is            902\n",
       "for           847\n",
       "be            761\n",
       "this          757\n",
       "I'm           738\n",
       "have          727\n",
       "your          690\n",
       "my            678\n",
       "dtype: int64"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counter(list(data['sentence']))[:25]\n",
    "\n",
    "# The majority of the top 25 most frequent words are either ponctuation or stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "b6718792",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_language(data):\n",
    "    \"\"\" Function that receives a dataset as input, and retrieves as an output the different \n",
    "    languages that exists inside the dataset and the number of lines in which the language\n",
    "    is detected.\n",
    "    \"\"\"    \n",
    "    \n",
    "    final_list=[]\n",
    "    for i in data.index:\n",
    "        _,_,detected_language= list(cld2.detect((data['sentence'][i])))\n",
    "        final_list.append(detected_language[0])\n",
    "    final_list\n",
    "    language_list = []\n",
    "    for i in range(len(final_list)):\n",
    "        temp_lang = language[i][0]\n",
    "        language_list.append(temp_lang)\n",
    "    language_list\n",
    "    return Counter(language_list).most_common()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "467ab3ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ENGLISH', 7375),\n",
       " ('Unknown', 6387),\n",
       " ('SCOTS', 79),\n",
       " ('X_PIG_LATIN', 21),\n",
       " ('ALBANIAN', 13),\n",
       " ('INTERLINGUA', 11),\n",
       " ('DANISH', 11),\n",
       " ('INDONESIAN', 8),\n",
       " ('CZECH', 8),\n",
       " ('PORTUGUESE', 7),\n",
       " ('FRENCH', 7),\n",
       " ('ROMANIAN', 6),\n",
       " ('TONGA', 6),\n",
       " ('INTERLINGUE', 4),\n",
       " ('FRISIAN', 4),\n",
       " ('YORUBA', 3),\n",
       " ('XHOSA', 3),\n",
       " ('KINYARWANDA', 3),\n",
       " ('SESELWA', 3),\n",
       " ('CATALAN', 3),\n",
       " ('RHAETO_ROMANCE', 3),\n",
       " ('FINNISH', 2),\n",
       " ('IRISH', 2),\n",
       " ('BISLAMA', 2),\n",
       " ('BRETON', 2),\n",
       " ('LATIN', 2),\n",
       " ('JAVANESE', 2),\n",
       " ('MAURITIAN_CREOLE', 2),\n",
       " ('NORWEGIAN', 2),\n",
       " ('SCOTS_GAELIC', 1),\n",
       " ('SPANISH', 1),\n",
       " ('LUXEMBOURGISH', 1),\n",
       " ('CORSICAN', 1),\n",
       " ('FAROESE', 1),\n",
       " ('WARAY_PHILIPPINES', 1),\n",
       " ('BASQUE', 1),\n",
       " ('VOLAPUK', 1),\n",
       " ('SLOVENIAN', 1),\n",
       " ('OCCITAN', 1),\n",
       " ('MANX', 1),\n",
       " ('HAUSA', 1),\n",
       " ('AFRIKAANS', 1),\n",
       " ('WOLOF', 1),\n",
       " ('HAWAIIAN', 1),\n",
       " ('HAITIAN_CREOLE', 1),\n",
       " ('AZERBAIJANI', 1),\n",
       " ('SLOVAK', 1),\n",
       " ('DUTCH', 1)]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_language(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "ed8ce897",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentence    You mean , people can hear me now ?\n",
       "emotion                                       7\n",
       "Name: 1345, dtype: object"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[1345]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002b9a4f",
   "metadata": {},
   "source": [
    "## Models as benchmark\n",
    "\n",
    "- **Weaker Baseline**: \n",
    "    - Pre-processing: Removing everything but letters, ‘?’ and ‘!’; stemming; stop word removal.\n",
    "    - CountVectorizer + KNN\n",
    "    - With Accuracy of 27%\n",
    "- **Stronger Baseline**:\n",
    "    - preprocessing\n",
    "    - CountVectorizer\n",
    "    - SVC ( Linear Kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596611a3",
   "metadata": {},
   "source": [
    "# NLP Pipeline - Weaker Baseline\n",
    "\n",
    "- Pre-processing: Removing everything but letters, ‘?’ and ‘!’; stemming; stop word removal.\n",
    "    - CountVectorizer + KNN\n",
    "    - With Accuracy of 27%\n",
    "\n",
    "## Initial Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7c582ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = set(stopwords.words('english'))\n",
    "exclude = set(string.punctuation)\n",
    "lemma = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d33c4fde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Size of unique stop words\n",
    "\n",
    "len(stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "98d3cb6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ponctuation unique characters inside exclude set\n",
    "\n",
    "len(exclude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "6b91c5be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm too old to be traded in .\""
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['sentence'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c977ad1",
   "metadata": {},
   "source": [
    "### Clean function\n",
    "\n",
    "- Lower cases\n",
    "- apply stemmatization/lemmatization \n",
    "- Remove numerical data and punctuation\n",
    "- Remove tags (with beautifulsoup)\n",
    "\n",
    "\n",
    "(tdqm - Instantly make your loops show a smart progress meter - just wrap any iterable with tqdm(iterable), and you're done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "540bd657",
   "metadata": {},
   "outputs": [],
   "source": [
    "snowball_stemmer = SnowballStemmer('english')\n",
    "\n",
    "def clean(text_list, lemmatize, stemmer):\n",
    "    \"\"\"\n",
    "    Function that a receives a list of strings and preprocesses it.\n",
    "    \n",
    "    :param text_list: List of strings.\n",
    "    :param lemmatize: Tag to apply lemmatization if True.\n",
    "    :param stemmer: Tag to apply the stemmer if True.\n",
    "    \"\"\"\n",
    "    updates = []\n",
    "    for j in tqdm(range(len(text_list))):\n",
    "        \n",
    "        text = text_list[j]\n",
    "        \n",
    "        #LOWERCASE TEXT\n",
    "        text = text.lower()\n",
    "        \n",
    "        #REMOVE NUMERICAL DATA AND PUNCTUATION\n",
    "        text = re.sub(\"[^a-zA-Z!?]\", ' ', text) # falta ? e !\n",
    "        \n",
    "        #REMOVE STOP WORDS\n",
    "        text = \" \".join([word for word in text.split() if word not in stop])\n",
    "        \n",
    "        #REMOVE TAGS\n",
    "        text = BeautifulSoup(text).get_text()\n",
    "        \n",
    "        if lemmatize:\n",
    "            text = \" \".join(lemma.lemmatize(word) for word in text.split())\n",
    "        \n",
    "        if stemmer:\n",
    "            text = \" \".join(snowball_stemmer.stem(word) for word in text.split())\n",
    "        \n",
    "        updates.append(text)\n",
    "        \n",
    "    return updates\n",
    "\n",
    "def update_df(dataframe, list_updated):\n",
    "    dataframe.update(pd.DataFrame({\"sentence\": list_updated}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "31172087",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gl/_jrjbthx3mdbjrh_13kh3xm80000gn/T/ipykernel_14903/1919345334.py:12: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for j in tqdm(range(len(text_list))):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c82a0257ad724dde80326b3a041d67ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Applying the cleaning function to the 'sentence' column of our dataset\n",
    "# Lemmer false\n",
    "# Stemmer true \n",
    "\n",
    "updated_data = clean(data['sentence'], lemmatize = False, stemmer = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "eec7d2aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>old trade</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mother said could alway tell ladi hand</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>alway said leav time came</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 sentence  emotion\n",
       "0                               old trade        6\n",
       "1  mother said could alway tell ladi hand        8\n",
       "2               alway said leav time came        6"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Update the data frame\n",
    "\n",
    "update_df(data, updated_data)\n",
    "data.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7cb77db",
   "metadata": {},
   "source": [
    "## Feature Extraction with bag-of-words\n",
    "\n",
    "- max_df -> When building the vocabulary ignore terms that have a document frequency strictly higher than the given threshold (corpus-specific stop words). If float, the parameter represents a proportion of documents, integer absolute counts. This parameter is ignored if vocabulary is not None."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0a49d778",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining CV\n",
    "\n",
    "cv = CountVectorizer(max_df=0.9, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ad476373",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cv.fit_transform(data[\"sentence\"])\n",
    "y = np.array(data['emotion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "183d3f87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14000, 5228)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17131510",
   "metadata": {},
   "source": [
    "## Training the model with KNN classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "de9369fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelknn = KNeighborsClassifier(n_neighbors=5, weights='distance', algorithm='brute', leaf_size=30, p=2,\n",
    "                                         metric='cosine', metric_params=None, n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "250f0455",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='brute', metric='cosine', n_jobs=1,\n",
       "                     weights='distance')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelknn.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51213656",
   "metadata": {},
   "source": [
    "## Testing the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d635bac7",
   "metadata": {},
   "source": [
    "### Applying the same pre-processing to the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "60b62b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gl/_jrjbthx3mdbjrh_13kh3xm80000gn/T/ipykernel_14903/1919345334.py:12: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for j in tqdm(range(len(text_list))):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "433d380b229c4303ac583e250a2f1970",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "updated_val = clean(val['sentence'], lemmatize = False, stemmer = True)\n",
    "update_df(val, updated_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0abaf512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cv transform no val set\n",
    "\n",
    "Val = cv.transform(val['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fd469d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = modelknn.predict(Val)\n",
    "y = np.array(val['emotion'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6634cd",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "772415ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.52      0.32      0.40       338\n",
      "           2       0.29      0.27      0.28       185\n",
      "           3       0.06      0.14      0.09        37\n",
      "           4       0.19      0.21      0.20        95\n",
      "           5       0.30      0.30      0.30        97\n",
      "           6       0.15      0.26      0.19        50\n",
      "           7       0.18      0.21      0.19        80\n",
      "           8       0.19      0.25      0.22       118\n",
      "\n",
      "    accuracy                           0.27      1000\n",
      "   macro avg       0.24      0.25      0.23      1000\n",
      "weighted avg       0.32      0.27      0.29      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (classification_report(predict, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9c3e46",
   "metadata": {},
   "source": [
    "## Models as benchmark\n",
    "\n",
    "- **Weaker Baseline**: \n",
    "    - Pre-processing: Removing everything but letters, ‘?’ and ‘!’; stemming; stop word removal.\n",
    "    - CountVectorizer + KNN\n",
    "    - With Accuracy of 27%\n",
    "- **Stronger Baseline**:\n",
    "    - preprocessing\n",
    "    - CountVectorizer\n",
    "    - SVC ( Linear Kernel)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9d1a5e",
   "metadata": {},
   "source": [
    "## Checking the present languages in the text - Pycld2 (UNDER CONSTRUCTION)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
